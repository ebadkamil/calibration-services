{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n",
    "from functools import partial\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from calibration import parse_ids\n",
    "from karabo_data import DataCollection, by_index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate dark offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dark_offset(module_number, path, *, pulse_ids=None):\n",
    "    \"\"\" Process Dark data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    module_number: int\n",
    "        Channel number between 0, 15\n",
    "    path: str\n",
    "        Path to Run folder\n",
    "    pulse_ids: str\n",
    "        For eg. \":\" to select all pulses in a train\n",
    "                \"start:stop:step\" to select indices with certain step size\n",
    "                \"1,2,3\" comma separated pulse index to select specific pulses\n",
    "                \"1,2,3, 5:10\" mix of above two\n",
    "        Default: all pulses \":\"\n",
    "        \n",
    "    Return\n",
    "    ------\n",
    "    out: ndarray\n",
    "        Shape: (n_pulses, ..., slow_scan, fast_scan)\n",
    "    \"\"\"\n",
    "\n",
    "    if not path or module_number not in range(16):\n",
    "        return\n",
    "\n",
    "    pattern = f\"(.+)LPD{module_number:02d}(.+)\"\n",
    "\n",
    "    files = [os.path.join(path, f) for f in os.listdir(path)\n",
    "             if f.endswith('.h5') and re.match(pattern, f)]\n",
    "\n",
    "    if not files:\n",
    "        return\n",
    "\n",
    "    run = DataCollection.from_paths(files)\n",
    "\n",
    "    module = [key for key in run.instrument_sources\n",
    "              if re.match(r\"(.+)/DET/(.+):(.+)\", key)]\n",
    "\n",
    "    if len(module) != 1:\n",
    "        return\n",
    "    \n",
    "    run = run.select([(module[0], \"image.data\")])\n",
    "    \n",
    "    pulse_ids = \":\" if pulse_ids is None else pulse_ids\n",
    "    pulses = parse_ids(pulse_ids)\n",
    "    \n",
    "    mean_image = 0\n",
    "    counts = 0\n",
    "    for tid, data in run.trains(devices=[(module[0], \"image.data\")], require_all=True):\n",
    "        image = np.squeeze(data[module[0]][\"image.data\"], axis=1) # (pulses, 1, ss, fs)\n",
    "        \n",
    "        if pulses != [-1]:\n",
    "            image = image[pulses, ...].astype(np.float32)\n",
    "        else:\n",
    "            image = image.astype(np.float32)\n",
    "        \n",
    "        mean_image += image\n",
    "        counts += 1\n",
    "     \n",
    "    return mean_image / counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules = \"0:16\"\n",
    "pulse_ids = \":\"\n",
    "dark_folder = \"path\"\n",
    "\n",
    "module_numbers = parse_ids(modules)\n",
    "print(module_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dark_eval = partial(dark_offset, \n",
    "                     path=dark_folder, \n",
    "                     pulse_ids=pulse_ids)\n",
    "\n",
    "dark_data = {}\n",
    "with ProcessPoolExecutor(max_workers=len(module_numbers)) as executor:\n",
    "    for modno, ret in zip(module_numbers, executor.map(_dark_eval, module_numbers)):\n",
    "        dark_data[modno] = ret\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write dark offset to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dark_data_file = \"path\"\n",
    "\n",
    "with h5py.File(dark_data, \"w\") as f:\n",
    "    for modno, data in dark_data.items():\n",
    "        g = f.create_group(f\"entry_1/instrument/module_{modno}\")\n",
    "        g.create_dataset('data', data=data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delay scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roi_intensity(module_number, path, *, pulse_ids=None, rois=None):\n",
    "    \n",
    "    if not path or module_number not in range(16):\n",
    "        return\n",
    "\n",
    "    pattern = f\"(.+)LPD{module_number:02d}(.+)\"\n",
    "\n",
    "    files = [os.path.join(path, f) for f in os.listdir(path)\n",
    "             if f.endswith('.h5') and re.match(pattern, f)]\n",
    "\n",
    "    if not files:\n",
    "        return\n",
    "\n",
    "    run = DataCollection.from_paths(files)\n",
    "\n",
    "    module = [key for key in run.instrument_sources\n",
    "              if re.match(r\"(.+)/DET/(.+):(.+)\", key)]\n",
    "\n",
    "    if len(module) != 1:\n",
    "        return\n",
    "    \n",
    "    run = run.select([(module[0], \"image.data\")])\n",
    "    \n",
    "    pulse_ids = \":\" if pulse_ids is None else pulse_ids\n",
    "    pulses = parse_ids(pulse_ids)\n",
    "    \n",
    "    intensities = OrderedDict()\n",
    "    for tid, data in run.trains(devices=[(module[0], \"image.data\")], require_all=True):\n",
    "        image = np.squeeze(data[module[0]][\"image.data\"], axis=1) # (pulses, 1, ss, fs)\n",
    "        \n",
    "        if rois is not None:\n",
    "            x0, x1, y0, y1 = rois\n",
    "            image = image[..., x0:x1, y0:y1]\n",
    "        \n",
    "        if pulses != [-1]:\n",
    "            image = image[pulses, ...].astype(np.float32)\n",
    "        else:\n",
    "            image = image.astype(np.float32)\n",
    "        \n",
    "        intensities[tid] = np.mean(image, axis=(-1,-2))\n",
    "    \n",
    "    return intensities"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "calibration-kernel",
   "language": "python",
   "name": "calibration-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
