{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n",
    "from functools import partial\n",
    "import h5py\n",
    "import multiprocessing as mp\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import time\n",
    "import xarray as xr\n",
    "from itertools import groupby\n",
    "\n",
    "\n",
    "from calibration import parse_ids\n",
    "from karabo_data import DataCollection, by_index, RunDirectory, stack_detector_data\n",
    "from karabo_data.geometry2 import LPD_1MGeometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate dark offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dark_offset(module_number, path, *, pulse_ids=None):\n",
    "    \"\"\" Process Dark data\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    module_number: int\n",
    "        Channel number between 0, 15\n",
    "    path: str\n",
    "        Path to Run folder\n",
    "    pulse_ids: str\n",
    "        For eg. \":\" to select all pulses in a train\n",
    "                \"start:stop:step\" to select indices with certain step size\n",
    "                \"1,2,3\" comma separated pulse index to select specific pulses\n",
    "                \"1,2,3, 5:10\" mix of above two\n",
    "        Default: all pulses \":\"\n",
    "        \n",
    "    Return\n",
    "    ------\n",
    "    out: ndarray\n",
    "        Shape: (n_pulses, ..., slow_scan, fast_scan)\n",
    "    \"\"\"\n",
    "\n",
    "    if not path or module_number not in range(16):\n",
    "        return\n",
    "\n",
    "    pattern = f\"(.+)LPD{module_number:02d}(.+)\"\n",
    "\n",
    "    files = [os.path.join(path, f) for f in os.listdir(path)\n",
    "             if f.endswith('.h5') and re.match(pattern, f)]\n",
    "\n",
    "    if not files:\n",
    "        return\n",
    "\n",
    "    run = DataCollection.from_paths(files)\n",
    "\n",
    "    module = [key for key in run.instrument_sources\n",
    "              if re.match(r\"(.+)/DET/(.+):(.+)\", key)]\n",
    "\n",
    "    if len(module) != 1:\n",
    "        return\n",
    "    \n",
    "    run = run.select([(module[0], \"image.data\")])\n",
    "    \n",
    "    pulse_ids = \":\" if pulse_ids is None else pulse_ids\n",
    "    pulses = parse_ids(pulse_ids)\n",
    "    \n",
    "    mean_image = 0\n",
    "    counts = 0\n",
    "    for tid, data in run.trains():\n",
    "        image = np.squeeze(data[module[0]][\"image.data\"], axis=1) # (pulses, 1, ss, fs)\n",
    "        \n",
    "        if image.shape[0] == 0:\n",
    "            continue\n",
    "        \n",
    "        if pulses != [-1]:\n",
    "            image = image[pulses, ...].astype(np.float32)\n",
    "        else:\n",
    "            image = image.astype(np.float32)\n",
    "              \n",
    "        mean_image += image\n",
    "        counts += 1\n",
    "    \n",
    "    if counts != 0:\n",
    "        return mean_image / counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]\n"
     ]
    }
   ],
   "source": [
    "modules = \"0:16\"\n",
    "pulse_ids = \"0:32\"\n",
    "\n",
    "highgain_dark_folder = \"/gpfs/exfel/exp/FXE/201931/p900089/raw/r0004\"\n",
    "mediumgain_dark_folder = \"/gpfs/exfel/exp/FXE/201931/p900089/raw/r0004\"\n",
    "lowgain_dark_folder = \"/gpfs/exfel/exp/FXE/201931/p900089/raw/r0004\"\n",
    "\n",
    "module_numbers = parse_ids(modules)\n",
    "\n",
    "dark_data = {\"high\":{}, \"medium\":{}, \"low\":{}}\n",
    "\n",
    "print(module_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High Gain dark evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dark_eval = partial(dark_offset, \n",
    "                     path=highgain_dark_folder, \n",
    "                     pulse_ids=pulse_ids)\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=len(module_numbers)) as executor:\n",
    "    for modno, ret in zip(module_numbers, executor.map(_dark_eval, module_numbers)):\n",
    "        dark_data[\"high\"][modno] = ret\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Medium Gain dark evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dark_eval = partial(dark_offset, \n",
    "                     path=mediumgain_dark_folder, \n",
    "                     pulse_ids=pulse_ids)\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=len(module_numbers)) as executor:\n",
    "    for modno, ret in zip(module_numbers, executor.map(_dark_eval, module_numbers)):\n",
    "        dark_data[\"medium\"][modno] = ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Low Gain dark evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "_dark_eval = partial(dark_offset, \n",
    "                     path=lowgain_dark_folder, \n",
    "                     pulse_ids=pulse_ids)\n",
    "\n",
    "with ProcessPoolExecutor(max_workers=len(module_numbers)) as executor:\n",
    "    for modno, ret in zip(module_numbers, executor.map(_dark_eval, module_numbers)):\n",
    "        dark_data[\"low\"][modno] = ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write dark offset to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dark_data_file = \"test.h5\"\n",
    "\n",
    "with h5py.File(dark_data_file, \"w\") as f:\n",
    "    for gain in dark_data.keys():\n",
    "        g = f.create_group(f\"entry_1/instrument/gain_{gain}\")\n",
    "        for modno, data in dark_data[gain].items():\n",
    "            if data is not None:\n",
    "                h = g.create_group(f\"module_{modno}\")\n",
    "                h.create_dataset('data', data=data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delay scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def module_roi_intensity(module_number, path, *, pulse_ids=None, rois=None):\n",
    "    \n",
    "    if not path or module_number not in range(16):\n",
    "        return\n",
    "\n",
    "    pattern = f\"(.+)LPD{module_number:02d}(.+)\"\n",
    "\n",
    "    files = [os.path.join(path, f) for f in os.listdir(path)\n",
    "             if f.endswith('.h5') and re.match(pattern, f)]\n",
    "\n",
    "    if not files:\n",
    "        return\n",
    "\n",
    "    run = DataCollection.from_paths(files)\n",
    "\n",
    "    module = [key for key in run.instrument_sources\n",
    "              if re.match(r\"(.+)/DET/(.+):(.+)\", key)]\n",
    "\n",
    "    if len(module) != 1:\n",
    "        return\n",
    "    \n",
    "    run = run.select([(module[0], \"image.data\")])\n",
    "    \n",
    "    pulse_ids = \":\" if pulse_ids is None else pulse_ids\n",
    "    pulses = parse_ids(pulse_ids)\n",
    "    \n",
    "    intensities = []\n",
    "    train_ids = []\n",
    "    for tid, data in run.trains():\n",
    "        image = np.squeeze(data[module[0]][\"image.data\"], axis=1) # (pulses, 1, ss, fs)\n",
    "        \n",
    "        if image.shape[0] == 0:\n",
    "            continue\n",
    "        \n",
    "        if rois is not None:\n",
    "            x0, x1, y0, y1 = rois\n",
    "            image = image[..., x0:x1, y0:y1]\n",
    "        \n",
    "        if pulses != [-1] and image.shape[0] != 0:\n",
    "            image = image[pulses, ...].astype(np.float32)\n",
    "        else:\n",
    "            image = image.astype(np.float32)\n",
    "        \n",
    "        intensities.append(np.mean(image, axis=(-1,-2)))\n",
    "        train_ids.append(tid)\n",
    "    \n",
    "    coords = {'trainId':np.array(train_ids)}\n",
    "    dims = ['trainId', 'dim_0']\n",
    "    data = xr.DataArray(np.stack(intensities), dims=dims, coords=coords)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modules = \"14, 15\"\n",
    "pulse_ids = \"1:10:2\"\n",
    "run_folder = \"/gpfs/exfel/exp/FXE/201931/p900089/raw/r0004\"\n",
    "\n",
    "rois = [0, 256, 0, 256]\n",
    "\n",
    "module_numbers = parse_ids(modules)\n",
    "print(module_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_roi_intensity_eval = partial(module_roi_intensity, \n",
    "                              path=run_folder, \n",
    "                              pulse_ids=pulse_ids,\n",
    "                              rois=rois)\n",
    "\n",
    "roi_intensities = {}\n",
    "with ProcessPoolExecutor(max_workers=len(module_numbers)) as executor:\n",
    "    for modno, ret in zip(\n",
    "        module_numbers, executor.map(_roi_intensity_eval, module_numbers)):\n",
    "        roi_intensities[modno] = ret\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_intensities[15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Delay arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delay_src = \"SA1_XTD2_XGM/DOOCS/MAIN\"\n",
    "delay_prop = \"beamPosition.ixPos.value\"\n",
    "\n",
    "run = RunDirectory(run_folder)\n",
    "\n",
    "# get delay data: xarray\n",
    "delay_data = run.get_array(delay_src, delay_prop)\n",
    "\n",
    "delay_data = delay_data.expand_dims('dim_1', axis=1)\n",
    "print(delay_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align delay data with ROI Intesities along TrainIds and plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import  matplotlib.pyplot as plt\n",
    "%matplotlib notebook\n",
    "\n",
    "pulse = 15\n",
    "\n",
    "for modno in module_numbers:\n",
    "    roi_int, delay = xr.align(roi_intensities[modno], delay_data)\n",
    "    \n",
    "    s = list(zip(delay[:, 0].values, roi_int[:, pulse].values))\n",
    "    roi_int_avg = []\n",
    "    roi_int_std = []\n",
    "    delay = []\n",
    "    for key, group in groupby(sorted(s), lambda x: x[0]):\n",
    "        x, y = zip(*group)\n",
    "        avg, std = np.mean(np.array(y)), np.std(np.array(y))\n",
    "        roi_int_avg.append(avg)\n",
    "        roi_int_std.append(std)\n",
    "        delay.append(x[0])        \n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax.errorbar(delay, roi_int_avg, yerr=roi_int_std, uplims=True, lolims=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LPD ROI intensity with Offset and Relative gain correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lpd_corrections(sequence, path, *, pulse_ids=None, rois=None, dark_data=None):\n",
    "    \n",
    "    if not path:\n",
    "        return\n",
    "\n",
    "    pattern = f\"(.+)LPD(.+)-S{sequence}\"\n",
    "\n",
    "    files = [os.path.join(path, f) for f in os.listdir(path)\n",
    "             if f.endswith('.h5') and re.match(pattern, f)]\n",
    "    if not files:\n",
    "        return\n",
    "    \n",
    "    devices = [(\"*/DET/*CH0:xtdf\", \"image.data\")]\n",
    "    run = DataCollection.from_paths(files).select(devices)\n",
    "    \n",
    "    pulse_ids = \":\" if pulse_ids is None else pulse_ids\n",
    "    pulses = parse_ids(pulse_ids)\n",
    "    \n",
    "    out_array = None\n",
    "    quad_positions = [[11.4, 299],\n",
    "                      [-11.5, 8],\n",
    "                      [254.5, -16],\n",
    "                      [278.5, 275]]\n",
    "    filename = os.path.join(\n",
    "        os.getcwd(),'calibration/geometries/lpd_mar_18_axesfixed.h5')\n",
    "\n",
    "    geom = LPD_1MGeometry.from_h5_file_and_quad_positions(\n",
    "        filename, quad_positions)\n",
    "    \n",
    "    mean = 0\n",
    "    count = 0\n",
    "    intensities = []\n",
    "    train_ids = []\n",
    "    \n",
    "    for tid, data in run.trains():\n",
    "        \n",
    "        def _corrections(source):\n",
    "            pattern = \"(.+)/DET/(.+)CH0:xtdf\"\n",
    "            modno = (re.match(pattern, source)).group(2)\n",
    "            \n",
    "            try:\n",
    "                image = np.squeeze(data[source][\"image.data\"], axis=1)\n",
    "            except KeyError as e:\n",
    "                return\n",
    "            \n",
    "            if pulses != [-1] and image.shape[0] != 0:\n",
    "                image = image[pulses, ...].astype(np.float32)\n",
    "            else:\n",
    "                image = image.astype(np.float32)\n",
    "                        \n",
    "            if dark_data is not None and image.shape[0] != 0:\n",
    "                high, medium, low = \\\n",
    "                    dark_data[\"high\"][modno], dark_data[\"medium\"][modno], dark_data[\"low\"][modno]\n",
    "                \n",
    "                if all([high is not None, medium is not None, low is not None]):\n",
    "                    currim = np.zeros_like(image)\n",
    "                    \n",
    "                    # High gain\n",
    "                    corrim = image - high\n",
    "                    currim[image <= 4096] = corrim[image <= 4096]\n",
    "                    \n",
    "                    # Medium gain\n",
    "                    corrim = (image - medium) * 9.85\n",
    "                    currim[(image <= 8192) & (image > 4096)] = \\\n",
    "                        corrim[(image <= 8192) & (image >4096)]\n",
    "                    \n",
    "                    # Low gain\n",
    "                    corrim = (image - low) * 9.85 * 7.44\n",
    "                    currim[image > 8192] = corrim[image > 8192]\n",
    "                    \n",
    "                    image = currim\n",
    "            \n",
    "            data[source][\"image.data\"] = image\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=len(data.keys())) as executor:\n",
    "            for source in data.keys():\n",
    "                executor.submit(_corrections, source)\n",
    "        \n",
    "        # assemble image        \n",
    "        try:\n",
    "            stacked_data = stack_detector_data(data, \"image.data\")  \n",
    "        except (ValueError, IndexError, KeyError) as e:\n",
    "            continue\n",
    "\n",
    "        n_images = (stacked_data.shape[0], )\n",
    "        if stacked_data.shape[0] == 0:\n",
    "            continue\n",
    "        \n",
    "        image_dtype = stacked_data.dtype\n",
    "        \n",
    "        if out_array is None:\n",
    "            out_array = geom.output_array_for_position_fast(\n",
    "                extra_shape=n_images, dtype=image_dtype)\n",
    "        \n",
    "        assembled, centre = geom.position_all_modules(\n",
    "                stacked_data, out=out_array)\n",
    "        \n",
    "        if rois is not None:\n",
    "            x0, x1, y0, y1 = rois\n",
    "            assembled = assembled[..., x0:x1, y0:y1]\n",
    "            \n",
    "        mean += assembled\n",
    "        count += 1\n",
    "        \n",
    "        intensities.append(np.nanmean(assembled, axis=(-1,-2)))\n",
    "        train_ids.append(tid)\n",
    "    \n",
    "    coords = {'trainId':np.array(train_ids)}\n",
    "    dims = ['trainId', 'dim_0']\n",
    "    data = xr.DataArray(np.stack(intensities), dims=dims, coords=coords)\n",
    "        \n",
    "    return mean / count, data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FXE_DET_LPD1M-1/DET/4CH0:xtdf 4\n",
      "FXE_DET_LPD1M-1/DET/12CH0:xtdf 12\n",
      "FXE_DET_LPD1M-1/DET/7CH0:xtdf 7\n",
      "FXE_DET_LPD1M-1/DET/14CH0:xtdf 14\n",
      "FXE_DET_LPD1M-1/DET/13CH0:xtdf 13\n",
      "FXE_DET_LPD1M-1/DET/6CH0:xtdf 6\n",
      "FXE_DET_LPD1M-1/DET/1CH0:xtdf 1\n",
      "FXE_DET_LPD1M-1/DET/5CH0:xtdf 5\n",
      "FXE_DET_LPD1M-1/DET/15CH0:xtdfFXE_DET_LPD1M-1/DET/10CH0:xtdf 10\n",
      "FXE_DET_LPD1M-1/DET/2CH0:xtdf 2\n",
      " FXE_DET_LPD1M-1/DET/3CH0:xtdf 3\n",
      "15\n",
      "FXE_DET_LPD1M-1/DET/11CH0:xtdf 11FXE_DET_LPD1M-1/DET/8CH0:xtdf 8\n",
      "\n",
      "FXE_DET_LPD1M-1/DET/9CH0:xtdf 9\n",
      "FXE_DET_LPD1M-1/DET/4CH0:xtdf FXE_DET_LPD1M-1/DET/12CH0:xtdf 12\n",
      "FXE_DET_LPD1M-1/DET/7CH0:xtdf 7\n",
      "FXE_DET_LPD1M-1/DET/14CH0:xtdf 14\n",
      "4\n",
      "FXE_DET_LPD1M-1/DET/13CH0:xtdf 13\n",
      "FXE_DET_LPD1M-1/DET/6CH0:xtdf 6\n",
      "FXE_DET_LPD1M-1/DET/1CH0:xtdf 1\n",
      "FXE_DET_LPD1M-1/DET/5CH0:xtdf 5\n",
      "FXE_DET_LPD1M-1/DET/15CH0:xtdf 15\n",
      "FXE_DET_LPD1M-1/DET/10CH0:xtdf 10\n",
      "FXE_DET_LPD1M-1/DET/2CH0:xtdf 2\n",
      "FXE_DET_LPD1M-1/DET/3CH0:xtdf FXE_DET_LPD1M-1/DET/11CH0:xtdf 11\n",
      "3\n",
      "FXE_DET_LPD1M-1/DET/8CH0:xtdf 8\n",
      "FXE_DET_LPD1M-1/DET/9CH0:xtdf 9\n",
      "FXE_DET_LPD1M-1/DET/4CH0:xtdf 4\n",
      "FXE_DET_LPD1M-1/DET/12CH0:xtdf FXE_DET_LPD1M-1/DET/7CH0:xtdf 7\n",
      "FXE_DET_LPD1M-1/DET/14CH0:xtdf 14\n",
      "12\n",
      "FXE_DET_LPD1M-1/DET/13CH0:xtdf 13\n",
      "FXE_DET_LPD1M-1/DET/6CH0:xtdf 6\n",
      "FXE_DET_LPD1M-1/DET/1CH0:xtdf 1\n",
      "FXE_DET_LPD1M-1/DET/5CH0:xtdf 5\n",
      "FXE_DET_LPD1M-1/DET/15CH0:xtdf 15\n",
      "FXE_DET_LPD1M-1/DET/10CH0:xtdf FXE_DET_LPD1M-1/DET/2CH0:xtdf 2\n",
      "10FXE_DET_LPD1M-1/DET/3CH0:xtdf 3\n",
      "FXE_DET_LPD1M-1/DET/11CH0:xtdf\n",
      " 11\n",
      "FXE_DET_LPD1M-1/DET/8CH0:xtdf 8\n",
      "FXE_DET_LPD1M-1/DET/9CH0:xtdf 9\n",
      "FXE_DET_LPD1M-1/DET/4CH0:xtdf 4\n",
      "FXE_DET_LPD1M-1/DET/12CH0:xtdf 12\n",
      "FXE_DET_LPD1M-1/DET/7CH0:xtdf 7\n",
      "FXE_DET_LPD1M-1/DET/14CH0:xtdf 14\n",
      "FXE_DET_LPD1M-1/DET/13CH0:xtdf 13\n",
      "FXE_DET_LPD1M-1/DET/6CH0:xtdf 6\n",
      "FXE_DET_LPD1M-1/DET/1CH0:xtdf 1\n",
      "FXE_DET_LPD1M-1/DET/5CH0:xtdf 5\n",
      "FXE_DET_LPD1M-1/DET/15CH0:xtdf 15\n",
      "FXE_DET_LPD1M-1/DET/10CH0:xtdf 10\n",
      "FXE_DET_LPD1M-1/DET/2CH0:xtdf 2\n",
      "FXE_DET_LPD1M-1/DET/3CH0:xtdf 3\n",
      "FXE_DET_LPD1M-1/DET/11CH0:xtdf 11\n",
      "FXE_DET_LPD1M-1/DET/8CH0:xtdf FXE_DET_LPD1M-1/DET/9CH0:xtdf 9\n",
      "8\n",
      "FXE_DET_LPD1M-1/DET/4CH0:xtdf 4\n",
      "FXE_DET_LPD1M-1/DET/12CH0:xtdf 12\n",
      "FXE_DET_LPD1M-1/DET/7CH0:xtdf 7\n",
      "FXE_DET_LPD1M-1/DET/14CH0:xtdf 14\n",
      "FXE_DET_LPD1M-1/DET/13CH0:xtdf 13\n",
      "FXE_DET_LPD1M-1/DET/6CH0:xtdf 6\n",
      "FXE_DET_LPD1M-1/DET/1CH0:xtdf 1\n",
      "FXE_DET_LPD1M-1/DET/5CH0:xtdf 5\n",
      "FXE_DET_LPD1M-1/DET/15CH0:xtdf 15\n",
      "FXE_DET_LPD1M-1/DET/10CH0:xtdf 10\n",
      "FXE_DET_LPD1M-1/DET/2CH0:xtdf 2\n",
      "FXE_DET_LPD1M-1/DET/3CH0:xtdf 3\n",
      "FXE_DET_LPD1M-1/DET/11CH0:xtdf 11\n",
      "FXE_DET_LPD1M-1/DET/8CH0:xtdf 8\n",
      "FXE_DET_LPD1M-1/DET/9CH0:xtdf 9\n",
      "FXE_DET_LPD1M-1/DET/4CH0:xtdf 4\n",
      "FXE_DET_LPD1M-1/DET/12CH0:xtdf 12\n",
      "FXE_DET_LPD1M-1/DET/7CH0:xtdf 7\n",
      "FXE_DET_LPD1M-1/DET/14CH0:xtdf 14\n",
      "FXE_DET_LPD1M-1/DET/13CH0:xtdf 13\n",
      "FXE_DET_LPD1M-1/DET/6CH0:xtdf 6\n",
      "FXE_DET_LPD1M-1/DET/1CH0:xtdf FXE_DET_LPD1M-1/DET/5CH0:xtdf1\n",
      "FXE_DET_LPD1M-1/DET/15CH0:xtdf  15\n",
      "5\n",
      "FXE_DET_LPD1M-1/DET/10CH0:xtdf 10FXE_DET_LPD1M-1/DET/2CH0:xtdf\n",
      " 2\n",
      "FXE_DET_LPD1M-1/DET/3CH0:xtdf 3\n",
      "FXE_DET_LPD1M-1/DET/11CH0:xtdf 11\n",
      "FXE_DET_LPD1M-1/DET/8CH0:xtdf 8\n",
      "FXE_DET_LPD1M-1/DET/9CH0:xtdf 9\n",
      "FXE_DET_LPD1M-1/DET/4CH0:xtdf 4\n",
      "FXE_DET_LPD1M-1/DET/12CH0:xtdf 12FXE_DET_LPD1M-1/DET/7CH0:xtdf 7\n",
      "FXE_DET_LPD1M-1/DET/14CH0:xtdf 14\n",
      "\n",
      "FXE_DET_LPD1M-1/DET/13CH0:xtdf 13\n",
      "FXE_DET_LPD1M-1/DET/6CH0:xtdf 6\n",
      "FXE_DET_LPD1M-1/DET/1CH0:xtdf 1\n",
      "FXE_DET_LPD1M-1/DET/5CH0:xtdf 5\n",
      "FXE_DET_LPD1M-1/DET/15CH0:xtdf FXE_DET_LPD1M-1/DET/10CH0:xtdf 10\n",
      "15\n",
      "FXE_DET_LPD1M-1/DET/2CH0:xtdf 2\n",
      "FXE_DET_LPD1M-1/DET/3CH0:xtdf 3\n",
      "FXE_DET_LPD1M-1/DET/11CH0:xtdf 11\n",
      "FXE_DET_LPD1M-1/DET/8CH0:xtdf 8\n",
      "FXE_DET_LPD1M-1/DET/9CH0:xtdf 9\n",
      "FXE_DET_LPD1M-1/DET/4CH0:xtdf 4\n",
      "FXE_DET_LPD1M-1/DET/12CH0:xtdf 12\n",
      "FXE_DET_LPD1M-1/DET/7CH0:xtdf 7\n",
      "FXE_DET_LPD1M-1/DET/14CH0:xtdfFXE_DET_LPD1M-1/DET/13CH0:xtdf FXE_DET_LPD1M-1/DET/6CH0:xtdf 14\n",
      "13\n",
      "FXE_DET_LPD1M-1/DET/1CH0:xtdf 1\n",
      " 6\n",
      "FXE_DET_LPD1M-1/DET/5CH0:xtdfFXE_DET_LPD1M-1/DET/15CH0:xtdf 15\n",
      "FXE_DET_LPD1M-1/DET/10CH0:xtdf 10 5\n",
      "FXE_DET_LPD1M-1/DET/2CH0:xtdf 2\n",
      "\n",
      "FXE_DET_LPD1M-1/DET/3CH0:xtdf 3\n",
      "FXE_DET_LPD1M-1/DET/11CH0:xtdf 11\n",
      "FXE_DET_LPD1M-1/DET/8CH0:xtdf 8\n",
      "FXE_DET_LPD1M-1/DET/9CH0:xtdf 9\n",
      "FXE_DET_LPD1M-1/DET/4CH0:xtdf 4\n",
      "FXE_DET_LPD1M-1/DET/12CH0:xtdfFXE_DET_LPD1M-1/DET/7CH0:xtdf 7\n",
      " FXE_DET_LPD1M-1/DET/14CH0:xtdfFXE_DET_LPD1M-1/DET/13CH0:xtdf 13\n",
      "FXE_DET_LPD1M-1/DET/6CH0:xtdf 6\n",
      "FXE_DET_LPD1M-1/DET/1CH0:xtdf 1\n",
      " 14\n",
      "12\n",
      "FXE_DET_LPD1M-1/DET/5CH0:xtdf FXE_DET_LPD1M-1/DET/15CH0:xtdf 15\n",
      "5\n",
      "FXE_DET_LPD1M-1/DET/10CH0:xtdf 10\n",
      "FXE_DET_LPD1M-1/DET/2CH0:xtdf 2\n",
      "FXE_DET_LPD1M-1/DET/3CH0:xtdf 3\n",
      "FXE_DET_LPD1M-1/DET/11CH0:xtdf 11\n",
      "FXE_DET_LPD1M-1/DET/8CH0:xtdf 8\n",
      "FXE_DET_LPD1M-1/DET/9CH0:xtdf 9\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-b171640c85ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m                           )\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lpd_corrections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# with ProcessPoolExecutor(max_workers=len(sequences)) as executor:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-33afb13ab213>\u001b[0m in \u001b[0;36mlpd_corrections\u001b[0;34m(sequence, path, pulse_ids, rois, dark_data)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mtrain_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mtid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrains\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m_corrections\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/calibration/lib/python3.6/site-packages/karabo_data/reader.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_all\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_data_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1297\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mtid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assemble_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/calibration/lib/python3.6/site-packages/karabo_data/reader.py\u001b[0m in \u001b[0;36m_assemble_data\u001b[0;34m(self, tid)\u001b[0m\n\u001b[1;32m   1286\u001b[0m                     \u001b[0msource_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1288\u001b[0;31m                     \u001b[0msource_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfirst\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mfirst\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/calibration/lib/python3.6/site-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0mmspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0mfspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0;31m# Patch up the output for NumPy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path = \"/gpfs/exfel/exp/FXE/201931/p900089/raw/r0004\"\n",
    "\n",
    "pattern = f\"(.+)LPD(.+)-S(.+).h5\"\n",
    "sequences = {re.match(pattern, f).group(3) for f in os.listdir(path)\n",
    "             if f.endswith('.h5') and re.match(pattern, f)}\n",
    "\n",
    "_lpd_corrections = partial(lpd_corrections, \n",
    "                           path=path,\n",
    "                           pulse_ids=\"1:10:2\"\n",
    "                          )\n",
    "\n",
    "mean = _lpd_corrections(list(sequences)[0])\n",
    "\n",
    "# with ProcessPoolExecutor(max_workers=len(sequences)) as executor:\n",
    "#     ret = executor.map(_lpd_corrections, list(sequences) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = RunDirectory(\"/gpfs/exfel/exp/FXE/201931/p900089/raw/r0004\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r.keys_for_source(\"SA1_XTD2_XGM/DOOCS/MAIN\")\n",
    "#r.get_array(\"SA1_XTD2_XGM/DOOCS/MAIN\", 'pulseEnergy.photonFlux.value')\n",
    "# dc = r.get_data_counts(\"FXE_DET_LPD1M-1/DET/12CH0:xtdf\", \"image.data\")\n",
    "# dc[dc != 0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "calibration-kernel",
   "language": "python",
   "name": "calibration-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
